import os
import yaml
import datetime
import pandas as pd
import numpy as np
import streamlit as st
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Literal, Any
import seaborn as sns
from matplotlib import cm, colors

from pyecharts import options as opts
from pyecharts.charts import Bar, Line, Kline
from streamlit_echarts import st_pyecharts
from pyecharts.commons.utils import JsCode

# Local Module (ä¿ç•™åŸæœ‰å¼•ç”¨)
try:
    from src.factor_eval.get_eval import EVALUATION
except ImportError:
    st.error("æ— æ³•å¯¼å…¥æœ¬åœ°æ¨¡å—: src.factor_eval.get_evalï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
    # åˆ›å»ºä¸€ä¸ª dummy ç±»é˜²æ­¢ IDE æŠ¥é”™ï¼Œå®é™…è¿è¡Œæ—¶ä¼šæŠ¥é”™åœæ­¢
    class EVALUATION:
        def __init__(self, *args, **kwargs): pass
        def calc_IC(self, method): return pd.DataFrame()
        def calc_grouped(self, quantile, bins): return pd.DataFrame(), pd.DataFrame()

# ------------------------------------------------------------------------
# Constants & Config
# ------------------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "data" # Path("./data")
RAW_DATA_PATH = DATA_DIR / "raw" / "all.parquet"
FACTOR_DIR = DATA_DIR / "factors"
DESC_PATH = DATA_DIR / "factor_desc.yaml"
# print(123, RAW_DATA_PATH, FACTOR_DIR, DESC_PATH)
# st.set_page_config(page_title="å•å› å­åˆ†æ", layout="wide")

# ------------------------------------------------------------------------
# 1. Data Loader
# ------------------------------------------------------------------------
@st.cache_data
def load_base_data() -> pd.DataFrame:
    """åŠ è½½åŸºç¡€è¡Œæƒ…æ•°æ®"""
    if not RAW_DATA_PATH.exists():
        st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {RAW_DATA_PATH}")
        return pd.DataFrame()
    return pd.read_parquet(RAW_DATA_PATH)

@st.cache_data
def load_factor_data(type_i: str, name: str) -> pd.DataFrame:
    """åŠ è½½å› å­æ•°æ®"""
    path = FACTOR_DIR / type_i / f"{name}.parquet"
    if not path.exists():
        st.error(f"å› å­æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return pd.DataFrame()
    return pd.read_parquet(path)

@st.cache_data
def load_factor_description(type_i: str, name: str) -> Dict[str, Any]:
    """åŠ è½½å› å­æè¿°æ–‡ä»¶"""
    if not DESC_PATH.exists():
        return {}
    with open(DESC_PATH, "r", encoding="utf-8") as f:
        desc_dict = yaml.safe_load(f) or {}
    return desc_dict.get(type_i, {}).get(name, {})

# ------------------------------------------------------------------------
# 2. Computation Logic
# ------------------------------------------------------------------------
@st.cache_data
def compute_ic(
    data: pd.DataFrame, 
    factor_df: pd.DataFrame, 
    ret_nd: List[int], 
    ic_type: Literal['IC', 'Rank-IC']
) -> pd.DataFrame:
    """è®¡ç®— IC æˆ– Rank-IC"""
    evaluator = EVALUATION(data, factor_df, ret_nd)
    method = 'pearson' if ic_type.lower() == 'ic' else 'spearman'
    return evaluator.calc_IC(method)

@st.cache_data
def compute_grouped(
    data: pd.DataFrame, 
    factor_df: pd.DataFrame, 
    ret_nd: List[int], 
    quantile: Optional[int] = 10, 
    bins: Optional[int] = None
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """è®¡ç®—åˆ†ç»„æ”¶ç›Šå’Œæè¿°ç»Ÿè®¡"""
    evaluator = EVALUATION(data, factor_df, ret_nd)
    return evaluator.calc_grouped(quantile, bins)

def calculate_hedged_curve(
    ret_series: pd.Series, 
    ret_horizon: int, 
    direction: str = 'L-S'
) -> pd.DataFrame:
    """
    è®¡ç®—åˆ†ç»„ç´¯è®¡å‡€å€¼åŠå¤šç©ºå¯¹å†²å‡€å€¼
    é€»è¾‘ä¼˜åŒ–ï¼šå…ˆç®—å‡ºæ”¶ç›Šç‡åºåˆ—ï¼Œå†è¿›è¡Œ cumprod
    """
    # 1. åŸå§‹åˆ†ç»„æ”¶ç›Š (ret_series æ˜¯ forward return)
    # å‡è®¾è¾“å…¥ ret_series index æ˜¯æ—¥æœŸ, columns æ˜¯ç»„åˆ«
    # éœ€è¦å°† forward return shift å›å»å¯¹é½æŒæœ‰æœŸï¼Œè¿™é‡Œå‡è®¾ä¼ å…¥çš„å·²ç»æ˜¯å¤„ç†å¥½çš„å•æœŸæ”¶ç›Š
    # å¦‚æœ evaluator.calc_grouped è¿”å›çš„æ˜¯æŒæœ‰æœŸæ”¶ç›Š(ä¾‹å¦‚5æ—¥æ”¶ç›Š)ï¼Œç»˜å›¾æ—¶éœ€è¦æ³¨æ„é¢‘ç‡
    
    # ç®€å•çš„å¤åˆ©è®¡ç®—: (1+r).cumprod()
    cum_nav = (ret_series + 1).cumprod()
    
    # 2. è®¡ç®—å¤šç©ºå¯¹å†² (Long - Short)
    # å¯¹å†²æ”¶ç›Šç‡ = å¤šå¤´ç»„æ”¶ç›Šç‡ - ç©ºå¤´ç»„æ”¶ç›Šç‡ (ä¸è€ƒè™‘èµ„é‡‘åˆ©ç”¨ç‡å‡åŠï¼Œçº¯çº¯çš„ alpha)
    cols = ret_series.columns
    long_col = cols[-1] if direction == 'L-S' else cols[0]
    short_col = cols[0] if direction == 'L-S' else cols[-1]
    
    hedged_ret = ret_series[long_col] - ret_series[short_col]
    hedged_col_name = f"{long_col}-{short_col}"
    
    # åˆå¹¶æ•°æ®
    final_df = cum_nav.copy()
    final_df[hedged_col_name] = (hedged_ret + 1).cumprod()
    
    # 3. å½’ä¸€åŒ–ï¼šèµ·å§‹ç‚¹è®¾ä¸º 1.0 (åœ¨æœ€æ—©æ—¥æœŸå‰è¡¥ä¸€å¤©)
    start_date = final_df.index[0] - datetime.timedelta(days=1)
    # åˆ›å»ºä¸€è¡Œ 1.0 çš„æ•°æ®
    initial_row = pd.DataFrame(1.0, index=[start_date], columns=final_df.columns)
    final_df = pd.concat([initial_row, final_df]).sort_index()
    
    return final_df.round(4)

# ------------------------------------------------------------------------
# 3. Plotting Functions
# ------------------------------------------------------------------------
def plot_ic_series(ic_df: pd.DataFrame):
    """ç»˜åˆ¶ IC æ—¶åºå›¾"""
    if ic_df.empty:
        st.warning("IC æ•°æ®ä¸ºç©º")
        return

    # è®¡ç®—ç´¯è®¡ IC
    cum_ic_df = ic_df.cumsum().round(3)
    
    # å‡†å¤‡ X è½´
    x_axis = ic_df.index.strftime("%Y-%m-%d").tolist()
    
    bar = Bar(init_opts=opts.InitOpts(width="100%", height="500px"))
    bar.add_xaxis(x_axis)

    # æ·»åŠ æŸ±çŠ¶å›¾ (IC)
    cols = ic_df.columns
    legend_selected = {}
    
    for i, col in enumerate(cols):
        is_active = (i == len(cols) - 1)  # é»˜è®¤åªæ˜¾ç¤ºæœ€åä¸€ä¸ªï¼ˆ22dï¼‰
        legend_selected[col] = is_active
        legend_selected[f"Cum{col}"] = is_active
        
        bar.add_yaxis(
            series_name=col,
            y_axis=ic_df[col].round(3).tolist(),
            label_opts=opts.LabelOpts(is_show=False),
            itemstyle_opts=opts.ItemStyleOpts(opacity=0.6 if not is_active else 1.0),
        )

    # æ·»åŠ æŠ˜çº¿å›¾ (CumIC) - å³è½´
    line = Line()
    line.add_xaxis(x_axis)
    
    for i, col in enumerate(cols):
        is_active = (i == len(cols) - 1)
        line.add_yaxis(
            series_name=f"Cum{col}",
            y_axis=cum_ic_df[col].tolist(),
            is_smooth=True,
            label_opts=opts.LabelOpts(is_show=False),
            yaxis_index=1,
            itemstyle_opts=opts.ItemStyleOpts(opacity=0.6 if not is_active else 1.0),
        )

    # ç»„åˆå›¾è¡¨
    bar.extend_axis(
        yaxis=opts.AxisOpts(
            name="Cum IC", type_="value", position="right", 
            splitline_opts=opts.SplitLineOpts(is_show=False)
        )
    )
    bar.overlap(line)
    bar.set_global_opts(
        title_opts=opts.TitleOpts(title="å› å­ IC æ—¶åº & ç´¯è®¡ IC"),
        xaxis_opts=opts.AxisOpts(type_="category"),
        yaxis_opts=opts.AxisOpts(name="IC Value", splitline_opts=opts.SplitLineOpts(is_show=True)),
        tooltip_opts=opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
        datazoom_opts=[opts.DataZoomOpts(range_start=0, range_end=100)],
        legend_opts=opts.LegendOpts(selected_map=legend_selected, pos_top="5%")
    )
    
    st_pyecharts(bar, height="500px")

def plot_factor_distribution(desc_df: pd.DataFrame):
    """ç»˜åˆ¶å› å­åˆ†å¸ƒå›¾ (Bar + Kline)"""
    if desc_df.empty:
        return

    # æ•°æ®é¢„å¤„ç†
    df = desc_df.copy()
    x_axis = df.index.astype(str).tolist()
    counts = df['count'].astype(int).tolist()
    
    # Kline data: [open, close, low, high] -> [25%, 75%, min, max]
    ohlc = df[['25%', '75%', 'min', 'max']].values.tolist()

    # 1. Bar (Counts)
    bar = Bar()
    bar.add_xaxis(x_axis)
    bar.add_yaxis(
        "æ ·æœ¬æ•°", counts, 
        yaxis_index=0,
        itemstyle_opts=opts.ItemStyleOpts(color="#91cc75", opacity=0.6)
    )

    # 2. Kline (Distribution)
    kline = Kline()
    kline.add_xaxis(x_axis)
    kline.add_yaxis(
        "å› å­åˆ†å¸ƒ", ohlc, 
        yaxis_index=1,
        itemstyle_opts=opts.ItemStyleOpts(color="#5470c6", color0="#5470c6", border_color="#5470c6", border_color0="#5470c6")
    )

    # 3. Combine
    bar.overlap(kline)
    bar.extend_axis(
        yaxis=opts.AxisOpts(
            name="å› å­å€¼", position="right", 
            splitline_opts=opts.SplitLineOpts(is_show=False)
        )
    )
    bar.set_global_opts(
        title_opts=opts.TitleOpts(title=""),
        xaxis_opts=opts.AxisOpts(name="Group"),
        yaxis_opts=opts.AxisOpts(name="Count", position="left"),
        tooltip_opts=opts.TooltipOpts(
            trigger="axis", 
            axis_pointer_type="cross",
            # è‡ªå®šä¹‰ tooltip é€»è¾‘ä¿æŒä¸å˜æˆ–ç®€åŒ–
            formatter=JsCode(
                """
                function (params) {
                    let res = '<b>Group: ' + params[0].axisValue + '</b><br/>';
                    params.forEach(function (item) {
                        if (item.seriesType === 'candlestick') {
                            res += item.marker + item.seriesName + '<br/>' +
                                'Max: ' + item.data[4].toFixed(3) + '<br/>' +
                                '75%: ' + item.data[2].toFixed(3) + '<br/>' +
                                '25%: ' + item.data[1].toFixed(3) + '<br/>' +
                                'Min: ' + item.data[3].toFixed(3) + '<br/>';
                        } else {
                            res += item.marker + item.seriesName + ': ' + item.data + '<br/>';
                        }
                    });
                    return res;
                }
                """
            )
        )
    )
    st_pyecharts(bar, height="400px")

def plot_cumulative_returns(nav_df: pd.DataFrame):
    """ç»˜åˆ¶åˆ†ç»„ç´¯è®¡æ”¶ç›Šæ›²çº¿"""
    if nav_df.empty:
        return

    line = Line()
    x_axis = nav_df.index.strftime("%Y-%m-%d").tolist()
    line.add_xaxis(x_axis)

    cols = nav_df.columns
    n_groups = len(cols) - 1 # æœ€åä¸€åˆ—æ˜¯å¯¹å†²
    
    # é¢œè‰²æ˜ å°„
    color_map = [colors.to_hex(cm.coolwarm(i / (n_groups - 1))) for i in range(n_groups)] if n_groups > 1 else ["#5470c6"]
    
    for i, col in enumerate(cols):
        is_hedged = (i == len(cols) - 1)
        
        # æ ·å¼é…ç½®
        if is_hedged:
            c = "black"
            width = 2.5
            opacity = 1.0
            line_type = "dashed"
        else:
            c = color_map[i]
            width = 2
            opacity = 1.0 if i in [0, n_groups-1] else 0.3 # çªå‡ºé¦–å°¾ç»„
            line_type = "solid"

        line.add_yaxis(
            series_name=col,
            y_axis=nav_df[col].tolist(),
            is_smooth=False,
            symbol="none",
            linestyle_opts=opts.LineStyleOpts(width=width, opacity=opacity, color=c, type_=line_type),
            itemstyle_opts=opts.ItemStyleOpts(color=c)
        )

    line.set_global_opts(
        title_opts=opts.TitleOpts(title="åˆ†ç»„ç´¯è®¡å‡€å€¼æ›²çº¿"),
        xaxis_opts=opts.AxisOpts(type_="category"),
        yaxis_opts=opts.AxisOpts(name="Net Value", is_scale=True, splitline_opts=opts.SplitLineOpts(is_show=True)),
        tooltip_opts=opts.TooltipOpts(trigger="axis"),
        datazoom_opts=[opts.DataZoomOpts(range_start=0, range_end=100)],
    )
    st_pyecharts(line, height="600px")


# ------------------------------------------------------------------------
# 4. Main Application
# ------------------------------------------------------------------------
def main():
    # --- Sidebar Control ---
    st.sidebar.title("Configuration")
    
    # Factor Selection
    st.sidebar.subheader("1. å› å­é€‰æ‹©")
    if not FACTOR_DIR.exists():
        st.sidebar.error(f"ç›®å½•ä¸å­˜åœ¨: {FACTOR_DIR}")
        return

    factor_types = [d.name for d in FACTOR_DIR.iterdir() if d.is_dir()]
    selected_type = st.sidebar.selectbox("å› å­å¤§ç±»", factor_types, index=1 if factor_types else None)
    
    factor_names = []
    if selected_type:
        type_path = FACTOR_DIR / selected_type
        factor_names = [f.stem for f in type_path.glob("*.parquet")]
    selected_name = st.sidebar.selectbox("å…·ä½“å› å­", factor_names)

    # Date Selection
    st.sidebar.subheader("2. æ—¶é—´èŒƒå›´")
    # é»˜è®¤å€¼ï¼Œå®é™…åº”ä»æ•°æ®ä¸­è·å–
    default_start = datetime.date(2024, 1, 1)
    default_end = datetime.date.today()
    date_range = st.sidebar.date_input("é€‰æ‹©æ—¥æœŸåŒºé—´", [default_start, default_end])
    
    if len(date_range) == 2:
        start_date, end_date = date_range
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
    else:
        st.sidebar.warning("è¯·é€‰æ‹©å®Œæ•´çš„èµ·æ­¢æ—¥æœŸ")
        return

    # Analysis Params
    st.sidebar.subheader("3. åˆ†æå‚æ•°")
    ic_mode = st.sidebar.radio("IC ç±»å‹", ['IC', 'Rank-IC'], horizontal=True)
    
    ret_lags_str = st.sidebar.text_input("æ”¶ç›Šç‡å‘¨æœŸ (é€—å·åˆ†éš”)", "1, 5, 10, 22")
    try:
        ret_nds = [int(x.strip()) for x in ret_lags_str.split(',') if x.strip().isdigit()]
    except:
        ret_nds = [1, 5, 10]
        
    group_mode = st.sidebar.selectbox("åˆ†ç»„æ–¹å¼", ["Quantile", "Bins"])
    group_num = st.sidebar.number_input("åˆ†ç»„æ•°é‡", min_value=2, max_value=50, value=10)

    # --- Main Content ---
    st.title(f"{selected_name}")
    st.markdown("___")

    # 1. Load Data
    with st.spinner("Loading Data..."):
        full_data = load_base_data()
        full_factor = load_factor_data(selected_type, selected_name)
        
        if full_data.empty or full_factor.empty:
            st.error("æ•°æ®åŠ è½½å¤±è´¥")
            return

        # Slicing
        data = full_data.loc[start_date_str:end_date_str]
        factor_df = full_factor.loc[start_date_str:end_date_str]
        
        if data.empty or factor_df.empty:
            st.warning("é€‰å®šåŒºé—´æ— æ•°æ®")
            return

    # 2. Factor Description
    st.subheader("ğŸ“Œ å› å­æè¿°")
    desc = load_factor_description(selected_type, selected_name)
    if desc:
        c1, c2 = st.columns([2, 1])
        with c1:
            st.markdown(f"**Description**: {desc.get('description', 'N/A')}")
            st.markdown(f"**Formula**:")
            if desc.get('formula'):
                st.latex(desc['formula'])
        with c2:
            st.markdown(f"**Category**: `{desc.get('category', 'N/A')}`")
            st.markdown(f"**Reference**: `{desc.get('reference', 'N/A')}`")
    
    with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ® (10 Rows)"):
        st.dataframe(factor_df.head(10).style.format("{:.4f}"))

    # 3. IC Analysis
    st.markdown("---")
    st.subheader("ğŸ“Š IC åˆ†æ")
    
    ic_df = compute_ic(data, factor_df, ret_nds, ic_mode)
    # æŒ‰æ—¶é—´åˆ‡ç‰‡ï¼Œå› ä¸º EVALUATION è®¡ç®—å¯èƒ½åŒ…å«æ‰€æœ‰æ—¶é—´
    ic_df = ic_df.loc[start_date_str:end_date_str]
    plot_ic_series(ic_df)
    
    # IC ç»Ÿè®¡è¡¨
    st.markdown("**IC ç»Ÿè®¡æ‘˜è¦**")
    ic_stats = pd.DataFrame({
        'Mean': ic_df.mean(),
        'Std': ic_df.std(),
        'IR': ic_df.mean() / ic_df.std(),
        'Win Rate': (ic_df > 0).mean()
    }).T
    # st.dataframe(ic_stats.style.format("{:.3f}"))#.background_gradient(cmap='RdYlGn', axis=1)

    # è·å– seaborn çš„è‰²æ¿å¯¹è±¡
    cm = sns.diverging_palette(240, 10, as_cmap=True)
    html_string = ic_stats.style.format("{:.3f}").background_gradient(cmap=cm, axis=1).set_properties(**{'font-size': '18px', 'text-align': 'center'}).to_html()
    # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è®©è¡¨å¤´ä¹Ÿå˜å¤§
    html_string = html_string.replace('<th>', '<th style="font-size: 22px; text-align: center">')
    st.markdown(html_string, unsafe_allow_html=True)



    # 4. Grouped Analysis
    st.markdown("---")
    st.subheader("ğŸ“ˆ åˆ†ç»„å›æµ‹")

    params = {'quantile': group_num, 'bins': None} if group_mode == "Quantile" else {'quantile': None, 'bins': group_num}
    
    desc_df, ret_grouped_df = compute_grouped(data, factor_df, ret_nds, **params)
    
    # 4.1 åˆ†å¸ƒå›¾
    st.markdown("#### å› å­åˆ†å±‚åˆ†å¸ƒ")
    plot_factor_distribution(desc_df)
    
    # 4.2 å‡€å€¼æ›²çº¿
    st.markdown("#### åˆ†ç»„ç´¯è®¡å‡€å€¼")
    cols = st.columns(5)
    with cols[0]:
        selected_lag = st.selectbox("é€‰æ‹©å›æµ‹å‘¨æœŸ (Ret Lag)", ret_grouped_df.columns, index=0)
    with cols[1]:
        ls_dir = st.radio("å¯¹å†²æ–¹å‘", ["Long-Short (L-S)", "Short-Long (S-L)"], horizontal=True)
    direction_code = 'L-S' if ls_dir.startswith('L') else 'S-L'

    # å¤„ç†æ”¶ç›Šç‡æ•°æ®
    # å‡è®¾ ret_grouped_df æ˜¯ MultiIndex æˆ–è€…åˆ—ååŒ…å«å‘¨æœŸä¿¡æ¯
    # è¿™é‡Œæ ¹æ®åŸä»£ç é€»è¾‘æå–ç‰¹å®šå‘¨æœŸçš„ Series
    try:
        # æå–ç‰¹å®šå‘¨æœŸçš„åˆ†ç»„æ”¶ç›Šï¼Œå‡è®¾ç»“æ„ä¸º: Index=Date, Columns=[Lag1_G1, Lag1_G2...] æˆ– MultiIndex
        # åŸä»£ç é€»è¾‘è¾ƒä¸ºç‰¹å®šï¼Œè¿™é‡Œåšé€šç”¨å‡è®¾ï¼šret_grouped_df åˆ—åä¸º '1d', '5d' ç­‰ï¼Œå€¼ä¸º list æˆ– dict
        # ä½†é€šå¸¸ grouped_ret æ˜¯ DataFrame: index=date, columns=MultiIndex(lag, group)
        
        # å‡è®¾ evaluator è¿”å›çš„æ˜¯ï¼šåˆ—ä¸º (lag, group) çš„ DataFrame
        if isinstance(ret_grouped_df.columns, pd.MultiIndex):
            # å–å‡ºé€‰å®š lag çš„æ•°æ®
            subset = ret_grouped_df[selected_lag] # å¾—åˆ° columns ä¸º group çš„ df
        else:
            # å…¼å®¹åŸä»£ç çš„æŸäº›ç‰¹å®šè¿”å›ç»“æ„ï¼Œå¦‚æœ evaluator è¿”å›çš„æ˜¯ Series åŒ…å« dict ç­‰
            # è¿™é‡Œæš‚æ—¶ä¿ç•™åŸä»£ç é€»è¾‘çš„å½±å­ï¼Œä½†å»ºè®® evaluator è¿”å›æ ‡å‡† DF
            # ä¸‹é¢æ¨¡æ‹ŸåŸä»£ç çš„ unstack().T é€»è¾‘ï¼Œè§†å®é™…æ•°æ®ç»“æ„è€Œå®š
            # å‡è®¾: ret_grouped_df æ˜¯ index=date, columns=lag, values=åˆ†ç»„æ”¶ç›ŠSeries
            pass 
            # ï¼ï¼ï¼æ³¨æ„ï¼šç”±äºçœ‹ä¸åˆ° EVALUATION çš„å†…éƒ¨å®ç°ï¼Œè¿™é‡Œä½¿ç”¨åŸä»£ç é€»è¾‘è¿›è¡Œé€‚é…
            subset = ret_grouped_df[selected_lag].unstack().T.dropna()
        
        # é‡‡æ ·é¢‘ç‡å¤„ç†ï¼šå¦‚æœæŒæœ‰æœŸæ˜¯ 5å¤©ï¼Œç†è®ºä¸Šåº”æ¯5å¤©è°ƒä»“ï¼Œæˆ–è€…çœ‹æˆé‡å æ”¶ç›Š
        # ä¸ºäº†å±•ç¤ºç®€å•ï¼Œè¿™é‡ŒæŒ‰æ—¥å±•ç¤ºï¼Œä½†éœ€æ³¨æ„å¤åˆ©é€»è¾‘
        ret_horizon_days = int(''.join(filter(str.isdigit, str(selected_lag))))
        
        # é‡é‡‡æ ·ä»¥åŒ¹é…æŒæœ‰æœŸ (å¯é€‰ï¼ŒåŸä»£ç æœ‰ ::int(selected_nd[:-1]) é€»è¾‘)
        # å¦‚æœæ˜¯é‡å æ”¶ç›Šï¼Œç›´æ¥ cumprod ä¼šå¤¸å¤§ã€‚å¦‚æœæ˜¯å•æœŸç‹¬ç«‹æ”¶ç›Šï¼Œéœ€è¦é™é‡‡æ ·ã€‚
        # é‡‡ç”¨åŸä»£ç é€»è¾‘ï¼šé™é‡‡æ ·
        subset_resampled = subset.iloc[::ret_horizon_days]
        
        nav_data = calculate_hedged_curve(subset_resampled, ret_horizon_days, direction_code)
        
        # st.markdown(f"#### åˆ†ç»„ç´¯è®¡å‡€å€¼ ({selected_lag}, {direction_code})")
        plot_cumulative_returns(nav_data)
        
    except Exception as e:
        st.error(f"å¤„ç†åˆ†ç»„æ”¶ç›Šæ•°æ®æ—¶å‡ºé”™: {e}")
        st.write("Raw Data Debug:", ret_grouped_df.head())


main()